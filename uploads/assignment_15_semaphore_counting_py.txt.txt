#!/usr/bin/env python
# -*- coding: UTF-8 -*-
'''
Describe :
  Describes what the program does

Execute :
  python filename.py [option] [argument] ...
  ./filename.py [option] [argument] ...

Copyright :
  (C) <date> <name> ...

Reference :
  This code is in the public domain.
  Link : https://www.pythontutorial.net/python-concurrency/python-semaphore/

Other Links :
  https://stackoverflow.com/questions/25863101/python-urllib-urlopen-not-working
  https://stackoverflow.com/questions/35863595/what-does-read-in-urlopenhttp-read-do-urllib
  https://stackoverflow.com/questions/33470760/python-threads-object-append-to-list
'''
# importing the modules
import threading
import urllib.request
import ssl

MAX_CONCURRENT_DOWNLOADS = 4

# creating a Semaphore instance where count is MAX_CONCURRENT_DOWNLOADS
semaphore = threading.Semaphore(MAX_CONCURRENT_DOWNLOADS)

def download(url) :
  with semaphore :
    print(f"Downloading {url}...")

    # urllib.request.urlopen returns a file-like object, the read method of it will return the response body of that url.
    context = ssl._create_unverified_context()
    response = urllib.request.urlopen(url)
    html_source = response.read()
    
    print(f"Finished downloading {url}")

    return html_source

def main() :
  # URLs to download
  urls = [
    'https://www.ietf.org/rfc/rfc791.txt',
    'https://www.ietf.org/rfc/rfc792.txt',
    'https://www.ietf.org/rfc/rfc793.txt',
    'https://www.ietf.org/rfc/rfc794.txt',
    'https://www.ietf.org/rfc/rfc795.txt',
  ]

  # Create a thread for each download
  threads = []
  for url in urls:
    thread = threading.Thread(target=download, args=(url,))
    threads.append(thread)

  # start the threads
  for thread in threads :
    thread.start()

  # Wait for all threads to complete
  print('Waiting for threads to finish ...')
  for thread in threads:
    thread.join()

if __name__ == '__main__' :
  main()

